{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "# 使用headless无界面浏览器模式\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangdi/Desktop/A_share/venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: use options instead of chrome_options\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "date='2020-02-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##当日北向资金动向\n",
    "url='http://data.eastmoney.com/hsgtcg/hy.html'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "data_file= '/Users/zhangdi/Desktop/A_share/stock_daily/'+date+'/Bei_cash.csv'\n",
    "with open(data_file,'w',newline='',encoding='utf8') as wf:\n",
    "    writer = csv.writer(wf)\n",
    "    record=['名称','涨跌幅','今日持股股票只数','今日持股市值','今日持股占板块比','今日持股占北向资金比',\n",
    "            '今日增持股票只数','今日增持市值','今日增持市值增幅','今日增持占板块比','今日增持占北向资金比',\n",
    "           '增持最大股市值','增持最大股占股本比','减持最大股市值','减持最大股占股本比']\n",
    "    writer.writerow(record)\n",
    "    table=soup.find('table',attrs={'class':'tab1'})\n",
    "    rows=table.find_all('tr')\n",
    "    for row in rows:\n",
    "        record=[]\n",
    "        cols=row.find_all('td')\n",
    "        count=1\n",
    "        for col in cols:\n",
    "            if count==1 or count==3:\n",
    "                count+=1\n",
    "                continue\n",
    "            else:\n",
    "                count+=1\n",
    "                record.append(col.get_text().strip())\n",
    "        if len(record)==0:\n",
    "            continue\n",
    "        else:\n",
    "            writer.writerow(record)\n",
    "    driver.find_element_by_css_selector('[id=\"PageContgopage\"]').send_keys('2')\n",
    "    driver.find_element_by_css_selector('[class=\"btn_link\"]').click()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file,'a',newline='',encoding='utf8') as wf:\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    writer = csv.writer(wf)\n",
    "    table=soup.find('table',attrs={'class':'tab1'})\n",
    "    rows=table.find_all('tr')\n",
    "    for row in rows:\n",
    "        record=[]\n",
    "        cols=row.find_all('td')\n",
    "        count=1\n",
    "        for col in cols:\n",
    "            if count==1 or count==3:\n",
    "                count+=1\n",
    "                continue\n",
    "            else:\n",
    "                count+=1\n",
    "                record.append(col.get_text().strip())\n",
    "        if len(record)==0:\n",
    "            continue\n",
    "        else:\n",
    "            writer.writerow(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##行业资金流向\n",
    "url='http://data.eastmoney.com/bkzj/hy.html'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file= '/Users/zhangdi/Desktop/A_share/stock_daily/'+date+'/industry_cash.csv'\n",
    "with open(data_file,'w',newline='',encoding='utf8') as wf:\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    writer = csv.writer(wf)\n",
    "    record=['名称','今日涨跌幅','今日主力净流入净额','今日主力净流入净占比',\n",
    "            '今日超大单净流入净额','今日超大单净流入净占比',\n",
    "            '今日大单净流入净额','今日大单净流入净占比',\n",
    "            '今日中单净流入净额','今日中单净流入净占比',\n",
    "            '今日小单净流入净额','今日小单净流入净占比',\n",
    "            '主力净流入最大股']\n",
    "    writer.writerow(record)\n",
    "    table=soup.find('table',attrs={'class':'tab1'})\n",
    "    rows=table.find_all('tr')\n",
    "    for row in rows:\n",
    "        record=[]\n",
    "        cols=row.find_all('td')\n",
    "        count=1\n",
    "        for col in cols:\n",
    "            if count==1 or count==3:\n",
    "                count+=1\n",
    "                continue\n",
    "            else:\n",
    "                count+=1\n",
    "                record.append(col.get_text().strip())\n",
    "        if len(record)==0:\n",
    "            continue\n",
    "        else:\n",
    "            writer.writerow(record)\n",
    "    driver.find_element_by_css_selector('[id=\"PageContgopage\"]').send_keys('2')\n",
    "    driver.find_element_by_css_selector('[class=\"btn_link\"]').click()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file,'a',newline='',encoding='utf8') as wf:\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    writer = csv.writer(wf)\n",
    "    table=soup.find('table',attrs={'class':'tab1'})\n",
    "    rows=table.find_all('tr')\n",
    "    for row in rows:\n",
    "        record=[]\n",
    "        cols=row.find_all('td')\n",
    "        count=1\n",
    "        for col in cols:\n",
    "            if count==1 or count==3:\n",
    "                count+=1\n",
    "                continue\n",
    "            else:\n",
    "                count+=1\n",
    "                record.append(col.get_text().strip())\n",
    "        if len(record)==0:\n",
    "            continue\n",
    "        else:\n",
    "            writer.writerow(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##行业估值\n",
    "url='http://data.eastmoney.com/gzfx/hylist.html'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "data_file= '/Users/zhangdi/Desktop/A_share/stock_daily/'+date+'/industry_PE.csv'\n",
    "with open(data_file,'w',newline='',encoding='utf8') as wf:\n",
    "    writer = csv.writer(wf)\n",
    "    record=['行业','PE(TTM)','PE(静)','市净率','PEG值','市现率',\n",
    "            '市销率','平均市值(亿元)','个股数量','亏损家数']\n",
    "    writer.writerow(record)\n",
    "    table=soup.find('table',attrs={'class':'tab1'})\n",
    "    rows=table.find_all('tr')\n",
    "    for row in rows:\n",
    "        record=[]\n",
    "        cols=row.find_all('td')\n",
    "        count=1\n",
    "        for col in cols:\n",
    "            if count==1 or count==3:\n",
    "                count+=1\n",
    "                continue\n",
    "            else:\n",
    "                count+=1\n",
    "                record.append(col.get_text().strip())\n",
    "        if len(record)==0:\n",
    "            continue\n",
    "        else:\n",
    "            writer.writerow(record)\n",
    "    driver.find_element_by_css_selector('[id=\"PageContgopage\"]').send_keys('2')\n",
    "    driver.find_element_by_css_selector('[class=\"btn_link\"]').click()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file,'a',newline='',encoding='utf8') as wf:\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    writer = csv.writer(wf)\n",
    "    table=soup.find('table',attrs={'class':'tab1'})\n",
    "    rows=table.find_all('tr')\n",
    "    for row in rows:\n",
    "        record=[]\n",
    "        cols=row.find_all('td')\n",
    "        count=1\n",
    "        for col in cols:\n",
    "            if count==1 or count==3:\n",
    "                count+=1\n",
    "                continue\n",
    "            else:\n",
    "                count+=1\n",
    "                record.append(col.get_text().strip())\n",
    "        if len(record)==0:\n",
    "            continue\n",
    "        else:\n",
    "            writer.writerow(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "act",
   "language": "python",
   "name": "act"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
